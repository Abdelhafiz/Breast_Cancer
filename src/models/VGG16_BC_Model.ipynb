{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import keras.callbacks as cb\n",
    "import keras.utils.np_utils as np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras import applications # For easy loading the VGG_16 Model\n",
    "from skimage import color\n",
    "# Image loading and other helper functions\n",
    "import dwdii_bc_model_helper as bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_Prep(img_data):\n",
    "    \"\"\"\n",
    "    :param img_data: training or test images of shape [#images, height, width]\n",
    "    :return: the array transformed to the correct shape for the VGG network\n",
    "                shape = [#images, height, width, 3] transforms to rgb and reshapes\n",
    "    \"\"\"\n",
    "    images = np.zeros([len(img_data), img_data.shape[1], img_data.shape[2], 3])\n",
    "    for i in range(0, len(img_data)):\n",
    "        im = img_data[i]\n",
    "        im *= 255 # Orginal imagnet images were not rescaled\n",
    "        im = color.gray2rgb(im)\n",
    "        images[i] = im\n",
    "    return(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vgg16_bottleneck(trainPath, testPath, imagePath, modelPath, size, balance = True, verbose = True, verboseFreq = 50, valPath = 'None'):\n",
    "    # Loading data\n",
    "    metaTr, metaTr2, mCountsTr = bc.load_training_metadata(trainPath, balance, verbose)\n",
    "    lenTrain = len(metaTr)\n",
    "    X_train, Y_train = bc.load_data(trainPath, imagePath, maxData = lenTrain, verboseFreq = verboseFreq, imgResize=size)\n",
    "    \n",
    "    metaTest, meataT2, mCountsT = bc.load_training_metadata(testPath, balance, verbose)\n",
    "    lenTest = len(metaTest)\n",
    "    X_test, Y_test = bc.load_data(testPath, imagePath, maxData = lenTrain, verboseFreq = verboseFreq, imgResize=size)\n",
    "    \n",
    "    X_train = VGG_Prep(X_train)\n",
    "    X_test = VGG_Prep(X_test)\n",
    "        \n",
    "    print('Loading the VGG_16 Model')\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "        \n",
    "    # Generating the bottleneck features for the training data\n",
    "    print('Evaluating the VGG_16 Model on the Training Data')\n",
    "    bottleneck_features_train = model.predict(X_train)\n",
    "    \n",
    "    # Saving the bottleneck features for the training data\n",
    "    featuresTrain = os.path.join(modelPath, 'bottleneck_features_train.npy')\n",
    "    labelsTrain = os.path.join(modelPath, 'labels_train.npy')\n",
    "    np.save(open(featuresTrain, 'wb'), bottleneck_features_train)\n",
    "    np.save(open(labelsTrain, 'wb'), Y_train)\n",
    "\n",
    "    # Generating the bottleneck features for the test data\n",
    "    print('Evaluating the VGG_16 Model on the Test Data')\n",
    "    bottleneck_features_test = model.predict(X_test)\n",
    "    \n",
    "    # Saving the bottleneck features for the test data\n",
    "    featuresTrain = os.path.join(modelPath, 'bottleneck_features_test.npy')\n",
    "    labelsTrain = os.path.join(modelPath, 'labels_test.npy')\n",
    "    np.save(open(featuresTrain, 'wb'), bottleneck_features_test)\n",
    "    np.save(open(labelsTrain, 'wb'), Y_test)\n",
    "    \n",
    "    if valPath != 'None':\n",
    "        metaVal, metaV2, mCountsV = bc.load_training_metadata(valPath, verbose = verbose, balanceViaRemoval = False)\n",
    "        lenVal = len(metaVal)\n",
    "        X_val, Y_val = bc.load_data(valPath, imagePath, maxData = lenVal, verboseFreq = verboseFreq, imgResize=size)\n",
    "        X_val = VGG_Prep(X_val)\n",
    "        \n",
    "        # Generating the bottleneck features for the test data\n",
    "        print('Evaluating the VGG_16 Model on the Validataion Data')\n",
    "        bottleneck_features_val = model.predict(X_val)\n",
    "    \n",
    "        # Saving the bottleneck features for the test data\n",
    "        featuresVal = os.path.join(modelPath, 'bottleneck_features_validation.npy')\n",
    "        labelsVal = os.path.join(modelPath, 'labels_validation.npy')\n",
    "        np.save(open(featuresVal, 'wb'), bottleneck_features_val)\n",
    "        np.save(open(labelsVal, 'wb'), Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variables for loading the data\n",
    "imagePath = '../images/ddsm/png/'\n",
    "trainDataPath = '../images/ddsm/ddsm_train.csv'\n",
    "testDataPath = '../images/ddsm/ddsm_test.csv'\n",
    "valDataPath = '../images/ddsm/ddsm_val.csv'\n",
    "imgResize = (150, 150) # can go up to (224, 224)\n",
    "modelPath = '../model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Balance\n",
      "----------------\n",
      "benign 531\n",
      "malignant 739\n",
      "normal 2685\n",
      "balanaceViaRemoval.avgE: 1318\n",
      "balanaceViaRemoval.theshold: 1318.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 531\n",
      "malignant 739\n",
      "normal 862\n",
      "Raw Balance\n",
      "----------------\n",
      "benign 531\n",
      "malignant 739\n",
      "normal 2685\n",
      "balanaceViaRemoval.avgE: 1318\n",
      "balanaceViaRemoval.theshold: 1318.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 531\n",
      "malignant 739\n",
      "normal 862\n",
      "0.0000: A_0152_1.RIGHT_MLO.LJPEG.png\n",
      "0.0235: C_0112_1.LEFT_CC.LJPEG.png\n",
      "0.0469: C_0218_1.LEFT_MLO.LJPEG.png\n",
      "0.0704: B_3478_1.RIGHT_CC.LJPEG.png\n",
      "0.0938: A_0437_1.RIGHT_MLO.LJPEG.png\n",
      "0.1173: C_0301_1.RIGHT_MLO.LJPEG.png\n",
      "0.1407: A_1078_1.LEFT_MLO.LJPEG.png\n",
      "0.1642: B_3096_1.RIGHT_MLO.LJPEG.png\n",
      "0.1876: A_0114_1.RIGHT_CC.LJPEG.png\n",
      "0.2111: A_1060_1.RIGHT_CC.LJPEG.png\n",
      "0.2345: A_1020_1.LEFT_CC.LJPEG.png\n",
      "0.2580: C_0397_1.LEFT_MLO.LJPEG.png\n",
      "0.2814: A_1017_1.LEFT_MLO.LJPEG.png\n",
      "0.3049: C_0238_1.LEFT_MLO.LJPEG.png\n",
      "0.3283: A_0472_1.RIGHT_CC.LJPEG.png\n",
      "0.3518: B_3107_1.LEFT_CC.LJPEG.png\n",
      "0.3752: C_0169_1.RIGHT_MLO.LJPEG.png\n",
      "0.3987: C_0034_1.RIGHT_MLO.LJPEG.png\n",
      "0.4221: B_3055_1.RIGHT_CC.LJPEG.png\n",
      "0.4456: B_3175_1.LEFT_CC.LJPEG.png\n",
      "0.4690: A_1032_1.LEFT_CC.LJPEG.png\n",
      "0.4925: C_0250_1.RIGHT_MLO.LJPEG.png\n",
      "0.5159: A_0542_1.RIGHT_MLO.LJPEG.png\n",
      "0.5394: B_3633_1.LEFT_CC.LJPEG.png\n",
      "0.5629: C_0144_1.RIGHT_MLO.LJPEG.png\n",
      "0.5863: C_0045_1.RIGHT_CC.LJPEG.png\n",
      "0.6098: C_0418_1.LEFT_MLO.LJPEG.png\n",
      "0.6332: B_3107_1.LEFT_MLO.LJPEG.png\n",
      "0.6567: C_0207_1.LEFT_CC.LJPEG.png\n",
      "0.6801: C_0372_1.RIGHT_MLO.LJPEG.png\n",
      "0.7036: C_0183_1.RIGHT_MLO.LJPEG.png\n",
      "0.7270: B_3147_1.LEFT_MLO.LJPEG.png\n",
      "0.7505: A_0286_1.RIGHT_CC.LJPEG.png\n",
      "0.7739: C_0496_1.LEFT_MLO.LJPEG.png\n",
      "0.7974: C_0251_1.RIGHT_CC.LJPEG.png\n",
      "0.8208: C_0131_1.RIGHT_MLO.LJPEG.png\n",
      "0.8443: C_0508_1.RIGHT_CC.LJPEG.png\n",
      "0.8677: C_0334_1.RIGHT_MLO.LJPEG.png\n",
      "0.8912: B_3423_1.RIGHT_MLO.LJPEG.png\n",
      "0.9146: B_3063_1.RIGHT_MLO.LJPEG.png\n",
      "0.9381: C_0017_1.LEFT_MLO.LJPEG.png\n",
      "0.9615: C_0302_1.RIGHT_CC.LJPEG.png\n",
      "0.9850: C_0201_1.RIGHT_MLO.LJPEG.png\n",
      "Raw Balance\n",
      "----------------\n",
      "benign 142\n",
      "malignant 179\n",
      "normal 658\n",
      "balanaceViaRemoval.avgE: 326\n",
      "balanaceViaRemoval.theshold: 326.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 142\n",
      "malignant 179\n",
      "normal 215\n",
      "Raw Balance\n",
      "----------------\n",
      "benign 142\n",
      "malignant 179\n",
      "normal 658\n",
      "balanaceViaRemoval.avgE: 326\n",
      "balanaceViaRemoval.theshold: 326.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 142\n",
      "malignant 179\n",
      "normal 215\n",
      "0.0000: B_3380_1.RIGHT_MLO.LJPEG.png\n",
      "0.0235: A_1019_1.LEFT_CC.LJPEG.png\n",
      "0.0469: C_0388_1.RIGHT_MLO.LJPEG.png\n",
      "0.0704: B_3091_1.RIGHT_CC.LJPEG.png\n",
      "0.0938: C_0215_1.LEFT_MLO.LJPEG.png\n",
      "0.1173: A_0207_1.LEFT_MLO.LJPEG.png\n",
      "0.1407: B_3504_1.RIGHT_CC.LJPEG.png\n",
      "0.1642: B_3480_1.LEFT_CC.LJPEG.png\n",
      "0.1876: A_0362_1.LEFT_MLO.LJPEG.png\n",
      "0.2111: C_0308_1.RIGHT_MLO.LJPEG.png\n",
      "0.2345: A_1092_1.LEFT_MLO.LJPEG.png\n",
      "Loading the VGG_16 Model\n",
      "Evaluating the VGG_16 Model on the Training Data\n",
      "Evaluating the VGG_16 Model on the Test Data\n",
      "Raw Balance\n",
      "----------------\n",
      "benign 18\n",
      "malignant 34\n",
      "normal 142\n",
      "Raw Balance\n",
      "----------------\n",
      "benign 18\n",
      "malignant 34\n",
      "normal 142\n",
      "balanaceViaRemoval.avgE: 64\n",
      "balanaceViaRemoval.theshold: 64.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 18\n",
      "malignant 34\n",
      "normal 38\n",
      "0.0000: C_0062_1.LEFT_CC.LJPEG.png\n",
      "0.2577: C_0049_1.RIGHT_MLO.LJPEG.png\n",
      "Evaluating the VGG_16 Model on the Validataion Data\n"
     ]
    }
   ],
   "source": [
    "vgg16_bottleneck(trainDataPath, testDataPath, imagePath, modelPath, imgResize, \n",
    "                 balance = True, verbose = True, verboseFreq = 50, valPath = valDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(cb.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        batch_loss = logs.get('loss')\n",
    "        self.losses.append(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model(train_feats, train_lab, test_feats, test_lab, model_path, model_save, epoch = 50, batch = 64):\n",
    "    train_bottleneck = os.path.join(model_path, train_feats)\n",
    "    train_labels = os.path.join(model_path, train_lab)\n",
    "    test_bottleneck = os.path.join(model_path, test_feats)\n",
    "    test_labels = os.path.join(model_path, test_lab)\n",
    "    \n",
    "    history = LossHistory()\n",
    "    \n",
    "    X_train = np.load(train_bottleneck)\n",
    "    Y_train = np.load(train_labels)\n",
    "    Y_train = np_utils.to_categorical(Y_train, nb_classes=3)\n",
    "    \n",
    "    X_test = np.load(test_bottleneck)\n",
    "    Y_test = np.load(test_labels)\n",
    "    Y_test = np_utils.to_categorical(Y_test, nb_classes=3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    # try Adadelta and Adam\n",
    "    model.compile(optimizer='adadelta',\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              nb_epoch=epoch,\n",
    "              batch_size=batch,\n",
    "              callbacks=[history],\n",
    "              validation_data=(X_test, Y_test),\n",
    "              verbose=2)\n",
    "    \n",
    "    score = model.evaluate(X_test, Y_test, batch_size=16, verbose=0)\n",
    "\n",
    "    print \"Network's test score [loss, accuracy]: {0}\".format(score)\n",
    "    \n",
    "    model.save_weights(model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Locations for the bottleneck and labels files that we need\n",
    "modelPath = '../model/'\n",
    "train_bottleneck = 'bottleneck_features_train.npy'\n",
    "train_labels = 'labels_train.npy'\n",
    "test_bottleneck = 'bottleneck_features_test.npy'\n",
    "test_labels = 'labels_test.npy'\n",
    "validation_bottleneck = 'bottleneck_features_valdation.npy'\n",
    "validation_label = 'labels_validation.npy'\n",
    "top_model_weights_path = 'top_weights01.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2132 samples, validate on 536 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 4.5813 - acc: 0.4592 - val_loss: 2.1936 - val_acc: 0.5093\n",
      "Epoch 2/50\n",
      "0s - loss: 1.1091 - acc: 0.6102 - val_loss: 1.1547 - val_acc: 0.5392\n",
      "Epoch 3/50\n",
      "1s - loss: 0.6859 - acc: 0.7205 - val_loss: 1.1288 - val_acc: 0.5373\n",
      "Epoch 4/50\n",
      "1s - loss: 0.5272 - acc: 0.7880 - val_loss: 1.3420 - val_acc: 0.5504\n",
      "Epoch 5/50\n",
      "0s - loss: 0.4266 - acc: 0.8288 - val_loss: 1.2831 - val_acc: 0.5429\n",
      "Epoch 6/50\n",
      "0s - loss: 0.3469 - acc: 0.8565 - val_loss: 1.3129 - val_acc: 0.5504\n",
      "Epoch 7/50\n",
      "0s - loss: 0.2816 - acc: 0.8921 - val_loss: 1.3801 - val_acc: 0.5653\n",
      "Epoch 8/50\n",
      "0s - loss: 0.2236 - acc: 0.9264 - val_loss: 1.4412 - val_acc: 0.5653\n",
      "Epoch 9/50\n",
      "0s - loss: 0.1882 - acc: 0.9390 - val_loss: 1.4813 - val_acc: 0.5765\n",
      "Epoch 10/50\n",
      "0s - loss: 0.1466 - acc: 0.9536 - val_loss: 1.5087 - val_acc: 0.5485\n",
      "Epoch 11/50\n",
      "0s - loss: 0.1233 - acc: 0.9629 - val_loss: 1.6294 - val_acc: 0.5597\n",
      "Epoch 12/50\n",
      "0s - loss: 0.1039 - acc: 0.9676 - val_loss: 1.7408 - val_acc: 0.5653\n",
      "Epoch 13/50\n",
      "0s - loss: 0.0971 - acc: 0.9737 - val_loss: 1.7026 - val_acc: 0.5709\n",
      "Epoch 14/50\n",
      "0s - loss: 0.0895 - acc: 0.9747 - val_loss: 1.6455 - val_acc: 0.5858\n",
      "Epoch 15/50\n",
      "1s - loss: 0.0604 - acc: 0.9826 - val_loss: 1.7057 - val_acc: 0.5616\n",
      "Epoch 16/50\n",
      "0s - loss: 0.0604 - acc: 0.9831 - val_loss: 1.6713 - val_acc: 0.5951\n",
      "Epoch 17/50\n",
      "1s - loss: 0.0542 - acc: 0.9845 - val_loss: 1.8026 - val_acc: 0.5765\n",
      "Epoch 18/50\n",
      "0s - loss: 0.0485 - acc: 0.9887 - val_loss: 1.8654 - val_acc: 0.5951\n",
      "Epoch 19/50\n",
      "0s - loss: 0.0422 - acc: 0.9897 - val_loss: 1.9932 - val_acc: 0.5616\n",
      "Epoch 20/50\n",
      "0s - loss: 0.0347 - acc: 0.9906 - val_loss: 1.8421 - val_acc: 0.5709\n",
      "Epoch 21/50\n",
      "0s - loss: 0.0220 - acc: 0.9967 - val_loss: 1.9521 - val_acc: 0.5728\n",
      "Epoch 22/50\n",
      "0s - loss: 0.0228 - acc: 0.9958 - val_loss: 1.9608 - val_acc: 0.5802\n",
      "Epoch 23/50\n",
      "0s - loss: 0.0292 - acc: 0.9916 - val_loss: 1.9274 - val_acc: 0.5896\n",
      "Epoch 24/50\n",
      "0s - loss: 0.0173 - acc: 0.9967 - val_loss: 2.0350 - val_acc: 0.5728\n",
      "Epoch 25/50\n",
      "0s - loss: 0.0204 - acc: 0.9962 - val_loss: 2.1293 - val_acc: 0.5746\n",
      "Epoch 26/50\n",
      "0s - loss: 0.0216 - acc: 0.9958 - val_loss: 2.1808 - val_acc: 0.5877\n",
      "Epoch 27/50\n",
      "0s - loss: 0.0167 - acc: 0.9962 - val_loss: 2.1736 - val_acc: 0.5877\n",
      "Epoch 28/50\n",
      "0s - loss: 0.0184 - acc: 0.9934 - val_loss: 2.0832 - val_acc: 0.5970\n",
      "Epoch 29/50\n",
      "1s - loss: 0.0119 - acc: 0.9981 - val_loss: 2.1328 - val_acc: 0.5970\n",
      "Epoch 30/50\n",
      "0s - loss: 0.0157 - acc: 0.9953 - val_loss: 2.1464 - val_acc: 0.6045\n",
      "Epoch 31/50\n",
      "0s - loss: 0.0122 - acc: 0.9972 - val_loss: 2.2004 - val_acc: 0.5840\n",
      "Epoch 32/50\n",
      "0s - loss: 0.0091 - acc: 0.9986 - val_loss: 2.1637 - val_acc: 0.6045\n",
      "Epoch 33/50\n",
      "0s - loss: 0.0101 - acc: 0.9977 - val_loss: 2.2105 - val_acc: 0.5933\n",
      "Epoch 34/50\n",
      "0s - loss: 0.0105 - acc: 0.9972 - val_loss: 2.1329 - val_acc: 0.5933\n",
      "Epoch 35/50\n",
      "1s - loss: 0.0075 - acc: 0.9991 - val_loss: 2.1851 - val_acc: 0.6082\n",
      "Epoch 36/50\n",
      "0s - loss: 0.0104 - acc: 0.9981 - val_loss: 2.3859 - val_acc: 0.5746\n",
      "Epoch 37/50\n",
      "0s - loss: 0.0118 - acc: 0.9967 - val_loss: 2.2344 - val_acc: 0.5970\n",
      "Epoch 38/50\n",
      "1s - loss: 0.0070 - acc: 0.9977 - val_loss: 2.3217 - val_acc: 0.5784\n",
      "Epoch 39/50\n",
      "0s - loss: 0.0050 - acc: 1.0000 - val_loss: 2.2872 - val_acc: 0.6007\n",
      "Epoch 40/50\n",
      "1s - loss: 0.0092 - acc: 0.9972 - val_loss: 2.2672 - val_acc: 0.5877\n",
      "Epoch 41/50\n",
      "0s - loss: 0.0098 - acc: 0.9967 - val_loss: 2.2428 - val_acc: 0.6026\n",
      "Epoch 42/50\n",
      "1s - loss: 0.0042 - acc: 0.9995 - val_loss: 2.2624 - val_acc: 0.6007\n",
      "Epoch 43/50\n",
      "1s - loss: 0.0063 - acc: 0.9991 - val_loss: 2.2823 - val_acc: 0.6101\n",
      "Epoch 44/50\n",
      "1s - loss: 0.0054 - acc: 0.9991 - val_loss: 2.3477 - val_acc: 0.5840\n",
      "Epoch 45/50\n",
      "1s - loss: 0.0041 - acc: 0.9991 - val_loss: 2.4574 - val_acc: 0.5821\n",
      "Epoch 46/50\n",
      "1s - loss: 0.0108 - acc: 0.9972 - val_loss: 2.4641 - val_acc: 0.5933\n",
      "Epoch 47/50\n",
      "1s - loss: 0.0044 - acc: 0.9986 - val_loss: 2.4643 - val_acc: 0.5989\n",
      "Epoch 48/50\n",
      "1s - loss: 0.0028 - acc: 1.0000 - val_loss: 2.5550 - val_acc: 0.5746\n",
      "Epoch 49/50\n",
      "1s - loss: 0.0050 - acc: 0.9981 - val_loss: 2.4994 - val_acc: 0.5896\n",
      "Epoch 50/50\n",
      "1s - loss: 0.0045 - acc: 0.9991 - val_loss: 2.4609 - val_acc: 0.5858\n",
      "Network's test score [loss, accuracy]: [2.4609192387381595, 0.58582089552238803]\n"
     ]
    }
   ],
   "source": [
    "train_top_model(train_feats=train_bottleneck, train_lab=train_labels, test_feats=test_bottleneck, test_lab=test_labels,\n",
    "                model_path=modelPath, model_save=top_model_weights_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
