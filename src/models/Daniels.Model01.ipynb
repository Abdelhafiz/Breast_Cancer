{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import Image\n",
    "import gc\n",
    "import numpy as np # pip install numpy --upgrade \n",
    "import os\n",
    "import random\n",
    "from scipy import misc\n",
    "import string\n",
    "import time\n",
    "import sys\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# Set some Theano config before initializing\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cpu,floatX=float32,allow_gc=False,openmp=True\"\n",
    "import theano\n",
    "\n",
    "# MatPlotLib - Setup for Jupyter notebook output\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Our modules\n",
    "import dwdii_bc_model_helper as bc\n",
    "import bc_models as models\n",
    "\n",
    "# And Keras so we can emit the version\n",
    "import keras\n",
    "\n",
    "random.seed(20275)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python v2.7.6 (default, Jun 22 2015, 17:58:13) \n",
      "[GCC 4.8.2]\n",
      "Numpy v: 1.12.1\n",
      "keras v: 1.0.3\n",
      "device: cpu\n",
      "floatX: float32\n",
      "mode: FAST_RUN\n",
      "openmp: True\n",
      "allow_gc: False\n"
     ]
    }
   ],
   "source": [
    "# Print some upfront version and config settings\n",
    "print \"Python v\" + sys.version\n",
    "print \"Numpy v: \" + np.__version__\n",
    "print \"keras v: \" + keras.__version__\n",
    "print \"device:\", theano.config.device\n",
    "print \"floatX:\",  theano.config.floatX\n",
    "print \"mode:\", theano.config.mode\n",
    "print \"openmp:\", theano.config.openmp\n",
    "print \"allow_gc:\", theano.config.allow_gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePath = \"/root/bc_data/ddsm-png.25\"\n",
    "#imagePath = \"/root/bc_data/Data_Thresholded/DDSM\"\n",
    "trainImagePath = imagePath\n",
    "trainDataPath = \"../../data/ddsm_train.csv\"\n",
    "\n",
    "# 2 Class Experiment? \n",
    "# If not, then default is 3 class experiment\n",
    "normalVsAbnormal = True\n",
    "categories = bc.bcNumerics()\n",
    "thesePathos = None #[\"benign\", \"malignant\"]\n",
    "if(normalVsAbnormal):\n",
    "     categories = bc.bcNormVsAbnormNumerics()\n",
    "\n",
    "#\n",
    "# Simulated training data\n",
    "#\n",
    "#trainImagePath = \"/root/bc_data/simulated_images\"\n",
    "#trainDataPath = \"/root/bc_data/simulated_images/simulated_images.csv\"\n",
    "#trainImagePath = \"/root/bc_data/simulated_images_new\"\n",
    "#trainDataPath = \"/root/bc_data/simulated_images_new/simulated_images.csv\"\n",
    "\n",
    "# Test data is always from ddsm_test.csv\n",
    "testDataPath = \"../../data/ddsm_test.csv\"\n",
    "imgResize = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ddsm_test.csv', 'ddsm_train.csv', 'ddsm_val.csv', 'mias_all.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training and Test Data\n",
    "\n",
    "In this section, the training/validation data is loaded. The load_data function pre-balances the data set by removing images from over-represented emotion classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Balance\n",
      "----------------\n",
      "abnormal 1270\n",
      "normal 2685\n",
      "balanaceViaRemoval.avgE: 1977\n",
      "balanaceViaRemoval.theshold: 1977.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "abnormal 1270\n",
      "normal 1623\n"
     ]
    }
   ],
   "source": [
    "metaData, meta2, mCounts = bc.load_training_metadata(trainDataPath, balanceViaRemoval=True, verbose=True, \n",
    "                                                     normalVsAbnormal=normalVsAbnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Balance\n",
      "----------------\n",
      "abnormal 1270\n",
      "normal 2685\n",
      "balanaceViaRemoval.avgE: 1977\n",
      "balanaceViaRemoval.theshold: 1977.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "abnormal 1270\n",
      "normal 1623\n",
      "0.0000: A_0152_1.RIGHT_MLO.LJPEG.png\n",
      "0.0173: A_0229_1.RIGHT_CC.LJPEG.png\n",
      "0.0346: B_3073_1.RIGHT_MLO.LJPEG.png\n",
      "0.0518: C_0010_1.RIGHT_MLO.LJPEG.png\n",
      "0.0691: A_0609_1.RIGHT_MLO.LJPEG.png\n",
      "0.0864: B_3426_1.RIGHT_MLO.LJPEG.png\n",
      "0.1037: A_0079_1.RIGHT_MLO.LJPEG.png\n",
      "0.1210: B_3122_1.LEFT_MLO.LJPEG.png\n",
      "0.1383: C_0108_1.LEFT_MLO.LJPEG.png\n",
      "0.1555: C_0146_1.LEFT_CC.LJPEG.png\n",
      "0.1728: A_0318_1.RIGHT_CC.LJPEG.png\n",
      "0.1901: B_3659_1.RIGHT_CC.LJPEG.png\n",
      "0.2074: C_0488_1.RIGHT_CC.LJPEG.png\n",
      "0.2247: C_0015_1.RIGHT_MLO.LJPEG.png\n",
      "0.2420: C_0065_1.RIGHT_MLO.LJPEG.png\n",
      "0.2592: A_0294_1.LEFT_CC.LJPEG.png\n",
      "0.2765: A_0247_1.LEFT_MLO.LJPEG.png\n",
      "0.2938: B_3044_1.RIGHT_CC.LJPEG.png\n",
      "0.3111: B_3033_1.LEFT_CC.LJPEG.png\n",
      "0.3284: B_3085_1.LEFT_CC.LJPEG.png\n",
      "0.3457: B_3166_1.RIGHT_CC.LJPEG.png\n",
      "0.3629: B_3377_1.RIGHT_MLO.LJPEG.png\n",
      "0.3802: C_0391_1.RIGHT_CC.LJPEG.png\n",
      "0.3975: B_3067_1.RIGHT_CC.LJPEG.png\n",
      "0.4148: A_0247_1.RIGHT_CC.LJPEG.png\n",
      "0.4321: C_0392_1.RIGHT_MLO.LJPEG.png\n",
      "0.4494: B_3098_1.LEFT_MLO.LJPEG.png\n",
      "0.4666: A_0390_1.LEFT_CC.LJPEG.png\n",
      "0.4839: B_3495_1.LEFT_CC.LJPEG.png\n",
      "0.5012: C_0075_1.LEFT_CC.LJPEG.png\n",
      "0.5185: C_0490_1.RIGHT_MLO.LJPEG.png\n",
      "0.5358: A_0052_1.RIGHT_CC.LJPEG.png\n",
      "0.5531: A_0209_1.LEFT_MLO.LJPEG.png\n",
      "0.5703: C_0005_1.RIGHT_MLO.LJPEG.png\n",
      "0.5876: A_1022_1.LEFT_CC.LJPEG.png\n",
      "0.6049: C_0031_1.RIGHT_CC.LJPEG.png\n",
      "0.6222: A_0072_1.RIGHT_MLO.LJPEG.png\n",
      "0.6395: B_3024_1.LEFT_MLO.LJPEG.png\n",
      "0.6568: B_3020_1.RIGHT_CC.LJPEG.png\n",
      "0.6740: A_0584_1.RIGHT_MLO.LJPEG.png\n",
      "0.6913: C_0186_1.LEFT_MLO.LJPEG.png\n",
      "0.7086: C_0183_1.RIGHT_MLO.LJPEG.png\n",
      "0.7259: A_0416_1.RIGHT_CC.LJPEG.png\n",
      "0.7432: B_3471_1.LEFT_CC.LJPEG.png\n",
      "0.7605: B_3109_1.RIGHT_CC.LJPEG.png\n",
      "0.7777: B_3480_1.RIGHT_CC.LJPEG.png\n",
      "0.7950: A_1027_1.LEFT_CC.LJPEG.png\n",
      "0.8123: A_0304_1.RIGHT_CC.LJPEG.png\n",
      "0.8296: C_0488_1.LEFT_MLO.LJPEG.png\n",
      "0.8469: C_0102_1.RIGHT_MLO.LJPEG.png\n",
      "0.8642: B_3142_1.LEFT_MLO.LJPEG.png\n",
      "0.8814: C_0388_1.LEFT_CC.LJPEG.png\n",
      "0.8987: A_0490_1.LEFT_MLO.LJPEG.png\n",
      "0.9160: C_0329_1.RIGHT_CC.LJPEG.png\n",
      "0.9333: B_3502_1.LEFT_CC.LJPEG.png\n",
      "0.9506: A_0043_1.LEFT_CC.LJPEG.png\n",
      "0.9679: B_3457_1.LEFT_MLO.LJPEG.png\n",
      "0.9851: A_0201_1.LEFT_CC.LJPEG.png\n",
      "(2893, 150, 150)\n",
      "(2893, 1)\n"
     ]
    }
   ],
   "source": [
    "# Actually load some representative data for model experimentation\n",
    "maxData = len(metaData)\n",
    "X_data, Y_data = bc.load_data(trainDataPath, trainImagePath, \n",
    "                              categories=categories,\n",
    "                              maxData = maxData, \n",
    "                              verboseFreq = 50, \n",
    "                              imgResize=imgResize, \n",
    "                              thesePathos=thesePathos,\n",
    "                              normalVsAbnormal=normalVsAbnormal)\n",
    "print X_data.shape\n",
    "print Y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Balance\n",
      "----------------\n",
      "abnormal 321\n",
      "normal 658\n",
      "balanaceViaRemoval.avgE: 489\n",
      "balanaceViaRemoval.theshold: 489.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "abnormal 321\n",
      "normal 405\n",
      "0.0000: B_3380_1.RIGHT_MLO.LJPEG.png\n",
      "0.0173: C_0082_1.LEFT_CC.LJPEG.png\n",
      "0.0346: A_0359_1.LEFT_CC.LJPEG.png\n",
      "0.0518: B_3092_1.LEFT_MLO.LJPEG.png\n",
      "0.0691: B_3664_1.LEFT_MLO.LJPEG.png\n",
      "0.0864: A_0070_1.LEFT_CC.LJPEG.png\n",
      "0.1037: A_0567_1.RIGHT_MLO.LJPEG.png\n",
      "0.1210: A_0343_1.LEFT_MLO.LJPEG.png\n",
      "0.1383: A_1019_1.LEFT_MLO.LJPEG.png\n",
      "0.1555: B_3681_1.RIGHT_CC.LJPEG.png\n",
      "0.1728: A_1058_1.RIGHT_MLO.LJPEG.png\n",
      "0.1901: A_0135_1.RIGHT_MLO.LJPEG.png\n",
      "0.2074: B_3632_1.RIGHT_MLO.LJPEG.png\n",
      "0.2247: A_0116_1.RIGHT_CC.LJPEG.png\n",
      "0.2420: B_3039_1.LEFT_MLO.LJPEG.png\n",
      "(726, 150, 150)\n",
      "(726, 1)\n"
     ]
    }
   ],
   "source": [
    "# Actually load some representative data for model experimentation\n",
    "maxData = len(metaData)\n",
    "X_test, Y_test = bc.load_data(testDataPath, imagePath, \n",
    "                              categories=categories,\n",
    "                              maxData = maxData, \n",
    "                              verboseFreq = 50, \n",
    "                              imgResize=imgResize, \n",
    "                              thesePathos=thesePathos,\n",
    "                              normalVsAbnormal=normalVsAbnormal)\n",
    "print X_test.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will apply transformations to the existing images to increase of training data, as well as add a bit of noise in the hopes of improving the overall training activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8679, 150, 150)\n",
      "(8679, 1)\n"
     ]
    }
   ],
   "source": [
    "imgDataGenCount = 3\n",
    "transformCount = imgDataGenCount\n",
    "\n",
    "newImgs = np.zeros([X_data.shape[0] * transformCount, X_data.shape[1], X_data.shape[2]])\n",
    "newYs = np.zeros([Y_data.shape[0] * transformCount, Y_data.shape[1]], dtype=np.int8)\n",
    "print newImgs.shape\n",
    "print newYs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = X_data[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done', '2017-05-11 02:52:11.238588')\n"
     ]
    }
   ],
   "source": [
    "ndx = 0\n",
    "for i in range(X_data.shape[0]):\n",
    "    img = X_data[i]\n",
    "   \n",
    "    for n in range(imgDataGenCount):\n",
    "            imgX = models.imageDataGenTransform(img, Y_data[i])\n",
    "            imgX = imgX.reshape(150, 150)\n",
    "            \n",
    "            #print imgX.shape\n",
    "            newImgs[ndx] = imgX\n",
    "            newYs[ndx] = Y_data[i]\n",
    "            #misc.imsave(\"testX.png\", imgX)\n",
    "            ndx += 1    \n",
    "    \n",
    "    #break\n",
    "    \n",
    "print(\"Done\", str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11572, 150, 150)\n",
      "(11572, 1)\n"
     ]
    }
   ],
   "source": [
    "X_data2 = np.concatenate((X_data, newImgs))\n",
    "Y_data2 = np.concatenate((Y_data, newYs))\n",
    "print X_data2.shape\n",
    "print Y_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "performedTransforms = True\n",
    "if performedTransforms:\n",
    "    X_train = X_data2\n",
    "    Y_train = Y_data2\n",
    "else:\n",
    "    X_train = X_data\n",
    "    Y_train = Y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Test Set Distribution\n",
    "The following code segment splits the data into training and test data sets. Currently this is a standard 80/20 split for training and test respectively after performing a random shuffle using the unison_shuffled_copies help method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11572, 150, 150)\n",
      "(726, 150, 150)\n",
      "(11572, 1)\n",
      "(726, 1)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "\n",
    "print Y_train.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train Dist: defaultdict(<type 'int'>, {0: 6492, 1: 5080})\n",
      "Y_test Dist: defaultdict(<type 'int'>, {0: 405, 1: 321})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "def yDist(y):\n",
    "    bcCounts = collections.defaultdict(int)\n",
    "    for a in range(0, y.shape[0]):\n",
    "        bcCounts[y[a][0]] += 1\n",
    "    return bcCounts\n",
    "\n",
    "print \"Y_train Dist: \" + str(yDist(Y_train))\n",
    "print \"Y_test Dist: \" + str(yDist(Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abnormal': 1, 'normal': 0}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Load the bc array for our count in the model definition\n",
    "print categories\n",
    "print len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del sys.modules['bc_models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 32, 143, 143)2080        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 32, 143, 143)0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 32, 71, 71)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 32, 71, 71)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 32, 67, 67)  25632       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 32, 67, 67)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)      (None, 32, 33, 33)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 32, 33, 33)  0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)    (None, 64, 31, 31)  18496       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 64, 31, 31)  0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)      (None, 64, 15, 15)  0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)    (None, 64, 14, 14)  16448       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 64, 14, 14)  0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)      (None, 64, 7, 7)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 3136)        0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 64)          200768      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)          (None, 64)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 2)           130         activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)          (None, 2)           0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 263554\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "binary_crossentropy\n"
     ]
    }
   ],
   "source": [
    "# Construct the model using our help function\n",
    "import bc_models as models\n",
    "model = models.bc_model_v03(len(categories), verbose=True, \n",
    "                                        input_shape=(1,X_train.shape[1],X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "The following code segment trains the model using the run_network helper function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadWeights = False\n",
    "weightsFileName = \"dwdii-bc-v03-150-normVsAbnorm-13970-20170510.hdf5\"\n",
    "if loadWeights:\n",
    "    model.load_weights('weights/' + weightsFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape to the appropriate shape for the CNN input\n",
    "testX = X_test.reshape(X_test.shape[0], 1, X_test.shape[1],X_test.shape[2])\n",
    "trainX = X_train.reshape(X_train.shape[0], 1, X_train.shape[1],X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start: 2017-05-13 00:25:39.618429\n",
      "(11572, 2)\n",
      "(726, 2)\n",
      "Training model...\n",
      "Train on 11572 samples, validate on 726 samples\n",
      "Epoch 1/20\n",
      "11572/11572 [==============================] - 3606s - loss: 0.1004 - acc: 0.9657 - val_loss: 2.0031 - val_acc: 0.6309\n",
      "Epoch 2/20\n",
      "11572/11572 [==============================] - 3089s - loss: 0.0900 - acc: 0.9679 - val_loss: 2.2913 - val_acc: 0.6226\n",
      "Epoch 3/20\n",
      "11572/11572 [==============================] - 2989s - loss: 0.0908 - acc: 0.9700 - val_loss: 1.7025 - val_acc: 0.6322\n",
      "Epoch 4/20\n",
      "11572/11572 [==============================] - 3079s - loss: 0.0934 - acc: 0.9680 - val_loss: 1.9806 - val_acc: 0.6350\n",
      "Epoch 5/20\n",
      "11572/11572 [==============================] - 2984s - loss: 0.0973 - acc: 0.9689 - val_loss: 2.1039 - val_acc: 0.6295\n",
      "Epoch 6/20\n",
      "11572/11572 [==============================] - 2963s - loss: 0.0930 - acc: 0.9699 - val_loss: 2.4273 - val_acc: 0.6267\n",
      "Epoch 7/20\n",
      "11572/11572 [==============================] - 2978s - loss: 0.0895 - acc: 0.9703 - val_loss: 2.2059 - val_acc: 0.6336\n",
      "Epoch 8/20\n",
      "11572/11572 [==============================] - 3008s - loss: 0.0939 - acc: 0.9693 - val_loss: 2.3820 - val_acc: 0.6212\n",
      "Epoch 9/20\n",
      "11572/11572 [==============================] - 2973s - loss: 0.0948 - acc: 0.9696 - val_loss: 2.3852 - val_acc: 0.6074\n",
      "Epoch 10/20\n",
      "11572/11572 [==============================] - 3110s - loss: 0.0893 - acc: 0.9707 - val_loss: 2.0672 - val_acc: 0.6405\n",
      "Epoch 11/20\n",
      "11572/11572 [==============================] - 2959s - loss: 0.0883 - acc: 0.9712 - val_loss: 1.9734 - val_acc: 0.6309\n",
      "Epoch 12/20\n",
      "11572/11572 [==============================] - 2985s - loss: 0.0841 - acc: 0.9736 - val_loss: 2.0445 - val_acc: 0.6309\n",
      "Epoch 13/20\n",
      "11572/11572 [==============================] - 3267s - loss: 0.0754 - acc: 0.9761 - val_loss: 2.4665 - val_acc: 0.6295\n",
      "Epoch 14/20\n",
      "11572/11572 [==============================] - 3811s - loss: 0.0906 - acc: 0.9714 - val_loss: 2.4859 - val_acc: 0.6336\n",
      "Epoch 15/20\n",
      "11572/11572 [==============================] - 3659s - loss: 0.0947 - acc: 0.9733 - val_loss: 2.3889 - val_acc: 0.6185\n",
      "Epoch 16/20\n",
      "11572/11572 [==============================] - 4518s - loss: 0.0920 - acc: 0.9724 - val_loss: 2.6343 - val_acc: 0.6433\n",
      "Epoch 17/20\n",
      "11572/11572 [==============================] - 4513s - loss: 0.0848 - acc: 0.9759 - val_loss: 2.2053 - val_acc: 0.6322\n",
      "Epoch 18/20\n",
      "11572/11572 [==============================] - 3863s - loss: 0.0808 - acc: 0.9752 - val_loss: 1.9753 - val_acc: 0.6253\n",
      "Epoch 19/20\n",
      "11572/11572 [==============================] - 3653s - loss: 0.0826 - acc: 0.9761 - val_loss: 2.7205 - val_acc: 0.6240\n",
      "Epoch 20/20\n",
      "11572/11572 [==============================] - 3728s - loss: 0.0767 - acc: 0.9766 - val_loss: 2.5044 - val_acc: 0.6074\n",
      "Training duration : 67747.0615859\n",
      "Network's test score [loss, accuracy]: [2.5043631407840192, 0.6074380163647255]\n",
      "CNN Error: 39.26%\n"
     ]
    }
   ],
   "source": [
    "print \"Training start: \" + str(datetime.datetime.now())\n",
    "m, losses, acc = models.run_network([trainX, testX, Y_train, Y_test], model, batch=50, epochs=20, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models.plot_losses(losses, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileLossesPng = '../../figures/plot_losses-' + weightsFileName + '.png'\n",
    "plt.savefig(fileLossesPng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights/' + weightsFileName, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw DDSM Images\n",
    "\n",
    "Initial results based on \"normal\" being masked as \"benign\":\n",
    "* bc_model_v0 (150x150, 800/200): 182s - loss: 0.0560 - acc: 0.9813 - val_loss: 1.9918 - val_acc: 0.6800\n",
    "* bc_model_v0 (150x150, 2000/500): 473s - loss: 0.0288 - acc: 0.9925 - val_loss: 1.4040 - val_acc: 0.7260\n",
    "   * somewhat balanced, Y_train Dist {0: 1223, 1: 777}, Y_test Dist: {0: 321, 1: 179}\n",
    "\n",
    "Revised with \"normal\", \"benign\" and \"malignant\" labeled seperately:\n",
    "* bc_model_v0 (150x150, 1311/328): 298s - loss: 0.0411 - acc: 0.9786 - val_loss: 1.3713 - val_acc: 0.6616\n",
    "\n",
    "After creating fixed \"train\", \"test\" and \"validate\" data sets, using \"train\" and \"test\" as well as including the DDSM Benign cases:\n",
    "* bc_model_v0 (150x150, 1554/363, 03.27.2017): 264s - loss: 0.0512 - acc: 0.9730 - val_loss: 1.3120 - val_acc: 0.6116\n",
    "* bc_model_v0 (150x150, 2155/539, 04.02.2017): 362s - loss: 0.0600 - acc: 0.9763 - val_loss: 1.5315 - val_acc: 0.4805\n",
    "\n",
    "bc_model_v01 - categorical_crossentropy\n",
    "* bc_model_v01 (150x150, 2155/539, 04.03.2017): 361s - loss: 0.0935 - acc: 0.9800 - val_loss: 2.7872 - val_acc: 0.5065\n",
    "* bc_model_v01 (150x150, 2132/536, 04.05.2017): 369s - loss: 0.0718 - acc: 0.9794 - val_loss: 2.5604 - val_acc: 0.5243\n",
    "\n",
    "#### Thresholded Images\n",
    "\n",
    "Using the \"Data_Thresholded\" images\n",
    "* bc_model_v0 (150x150, Thresholded, 661/171, 03.28.2017): 124s - loss: 0.0529 - acc: 0.9743 - val_loss: 1.4331 - val_acc: 0.4971\n",
    "\n",
    "#### Simulated Images\n",
    "\n",
    "Using the \"simulated_images\" images\n",
    "* bc_model_v01 (150x150, 7776/536, 04.24.2017): 1250s - loss: 0.5543 - acc: 0.7885 - val_loss: 7.1153 - val_acc: 0.4123\n",
    "\n",
    "Using the \"simulated_images_new\" images\n",
    "* bc_model_v01 (150x150, 7776/536, 04.30.2017): 1242s - loss: 10.1318 - acc: 0.3714 - val_loss: 6.7477 - val_acc: 0.3340\n",
    "\n",
    "#### Normal Vs Abnormal\n",
    "\n",
    "##### Raw\n",
    "* bc_model_v01 (150x150, 2893/536, 04.25.2017):  496s - loss: 0.0522 - acc: 0.9865 - val_loss: 2.2328 - val_acc: 0.6309\n",
    "* bc_model_v03 (150x150, 11572/726, 05.10.2017, 30 epochs): 2938s - loss: 0.1378 - acc: 0.9468 - val_loss: 1.6165 - val_acc: 0.6061\n",
    "    * 40 epochs (+10): 2987s - loss: 0.1092 - acc: 0.9615 - val_loss: 2.0735 - val_acc: 0.6157\n",
    "    * 60 epochs (+20): 3728s - loss: 0.0767 - acc: 0.9766 - val_loss: 2.5044 - val_acc: 0.6074\n",
    "    \n",
    "##### Data Thresholded\n",
    "* bc_model_v01 (150x150, 924/231,04.26.2017): 154s - loss: 0.0365 - acc: 0.9892 - val_loss: 1.9738 - val_acc: 0.5628\n",
    "* bc_model_v01 (150x150, 2737/694,04.29.2017): 463s - loss: 0.0390 - acc: 0.9898 - val_loss: 2.4042 - val_acc: 0.6326\n",
    "* bc_model_v01 ((150x150, 5474/694,04.30.2017)): 1317s - loss: 0.0552 - acc: 0.9845 - val_loss: 2.8678 - val_acc: 0.6138\n",
    "\n",
    "#### Benign Vs Malignant\n",
    "\n",
    "##### Raw\n",
    "* bc_model_v01 (150x150, 13970/321, 05.05.2017, 50 epochs): 4376s - loss: 0.0163 - acc: 0.9961 - val_loss: 3.1204 - val_acc: 0.6480\n",
    "* bc_model_v02 (1 dropout, 13970/321, 05.06.2017, 30 epochs): 4678s - loss: 0.0222 - acc: 0.9941 - val_loss: 2.9720 - val_acc: 0.6978\n",
    "* bc_model_v03 (2 dropout, 13970/321, 05.07.2017, 30 epochs): 4771s - loss: 0.0419 - acc: 0.9896 - val_loss: 2.4619 - val_acc: 0.6667\n",
    "    * 35 Epochs (+5): 5833s - loss: 0.0355 - acc: 0.9911 - val_loss: 2.6903 - val_acc: 0.6667\n",
    "    * 45 Epochs (+10): 4686s - loss: 0.0355 - acc: 0.9908 - val_loss: 2.7548 - val_acc: 0.7165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultsValAcc = {}\n",
    "#resultsValAcc[\"1\"] = 0.6800\n",
    "#resultsValAcc[\"2\"] = 0.7260\n",
    "#resultsValAcc[\"3\"] = 0.6616\n",
    "#resultsValAcc[\"03-27-2017\"] = 0.6116\n",
    "#resultsValAcc[\"04-02-2017\"] = 0.4805\n",
    "#resultsValAcc[\"04-03-2017\"] = 0.5065\n",
    "#resultsValAcc[\"04-05-2017\"] = 0.5243\n",
    "resultsValAcc[924] = 0.5628\n",
    "resultsValAcc[2737] = 0.6326\n",
    "resultsValAcc[5474] = 0.6138\n",
    "import dwdii_test as dwdii\n",
    "#cmp = matplotlib.colors.Colormap(\"Blues\")\n",
    "dwdii.barChart(resultsValAcc, filename=\"../../figures/shallowCnn_thresholded_2class_results_valacc.png\", title=\"Shallow CNN - DDSM Data Thresholded 2 Class Test Accuracy\", yAxisLabel=\"Accuracy %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Predictions with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictOutput = model.predict(testX, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predClass = np.array(predictOutput[0]).argmax()\n",
    "numBC = bc.reverseDict(categories)\n",
    "numBC[predClass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numBC[Y_test[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predClasses = []\n",
    "for i in range(len(predictOutput)):\n",
    "\n",
    "    arPred = np.array(predictOutput[i])\n",
    "    predictionProb = arPred.max()\n",
    "    predictionNdx = arPred.argmax()\n",
    "    predClassName = numBC[predictionNdx]\n",
    "    predClasses.append(predictionNdx)\n",
    "\n",
    "    #print \"{0}: {1} ({2})\".format(i, predClassName, predictionProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use sklearn's helper method to generate the confusion matrix\n",
    "cnf_matrix = skm.confusion_matrix(Y_test, predClasses)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_names = numBC.values()\n",
    "print class_names[1:3]\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "fileCfMatrix = '../../figures/confusion_matrix-' + weightsFileName + '.png'\n",
    "plt.figure()\n",
    "bc.plot_confusion_matrix(cnf_matrix, classes=class_names[1:3],\n",
    "                      title='Confusion matrix, without normalization, \\n' + weightsFileName)\n",
    "plt.savefig(fileCfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the image we just saved\n",
    "from IPython.display import Image\n",
    "Image(filename=fileCfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "fileCfMatrixNorm = '../../figures/confusion_matrix_norm-' + weightsFileName + '.png'\n",
    "plt.figure()\n",
    "bc.plot_confusion_matrix(cnf_matrix, classes=class_names[1:3], normalize=True,\n",
    "                      title='Normalized confusion matrix \\n' + weightsFileName)\n",
    "plt.savefig(fileCfMatrixNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the image we just saved\n",
    "from IPython.display import Image\n",
    "Image(filename=fileCfMatrixNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
