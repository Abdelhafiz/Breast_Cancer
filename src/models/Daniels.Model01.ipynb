{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import Image\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy import misc\n",
    "import string\n",
    "import time\n",
    "\n",
    "# Set some Theano config before initializing\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cpu,floatX=float32,allow_gc=False,openmp=True\"\n",
    "import theano\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#import emotion_model\n",
    "import dwdii_bc_model_helper as bc\n",
    "import bc_models as models\n",
    "\n",
    "random.seed(20275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "floatX: float32\n",
      "mode: FAST_RUN\n",
      "openmp: True\n",
      "allow_gc: False\n"
     ]
    }
   ],
   "source": [
    "print \"device:\", theano.config.device\n",
    "print \"floatX:\",  theano.config.floatX\n",
    "print \"mode:\", theano.config.mode\n",
    "print \"openmp:\", theano.config.openmp\n",
    "print \"allow_gc:\", theano.config.allow_gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePath = \"/root/bc_data/ddsm-png.25\"\n",
    "dataPath = \"/root/bc_data/ddsm-png.25/Ddsm_png.csv\"\n",
    "imgResize = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ddsm', 'ddsm-hog', 'ddsm-png.25', 'ddsm-sm', 'Ddsm.csv', 'mias']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/root/bc_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training and Test Data\n",
    "\n",
    "In this section, the training/validation data is loaded. The load_data function pre-balances the data set by removing images from over-represented emotion classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Balancing\n",
      "----------------\n",
      "benign 3164\n",
      "malignant 1096\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 3164\n",
      "malignant 1096\n"
     ]
    }
   ],
   "source": [
    "metaData, meta2 = bc.load_training_metadata(dataPath, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta2[meta2.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Balancing\n",
      "----------------\n",
      "benign 3164\n",
      "malignant 1096\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 3164\n",
      "malignant 1096\n",
      "0.000000: A_0152_1.RIGHT_MLO.LJPEG.png\n",
      "0.050000: C_0128_1.RIGHT_MLO.LJPEG.png\n",
      "0.100000: B_3511_1.RIGHT_CC.LJPEG.png\n",
      "0.150000: A_0362_1.LEFT_CC.LJPEG.png\n",
      "0.200000: C_0022_1.RIGHT_MLO.LJPEG.png\n",
      "0.250000: B_3663_1.LEFT_MLO.LJPEG.png\n",
      "0.300000: A_1084_1.LEFT_CC.LJPEG.png\n",
      "0.350000: A_0235_1.RIGHT_MLO.LJPEG.png\n",
      "0.400000: A_0034_1.LEFT_CC.LJPEG.png\n",
      "0.450000: C_0027_1.LEFT_CC.LJPEG.png\n",
      "0.500000: A_1044_1.RIGHT_MLO.LJPEG.png\n",
      "0.550000: C_0230_1.LEFT_CC.LJPEG.png\n",
      "0.600000: B_3672_1.RIGHT_MLO.LJPEG.png\n",
      "0.650000: A_0091_1.LEFT_MLO.LJPEG.png\n",
      "0.700000: A_0508_1.LEFT_MLO.LJPEG.png\n",
      "0.750000: B_3019_1.RIGHT_CC.LJPEG.png\n",
      "0.800000: A_0490_1.RIGHT_CC.LJPEG.png\n",
      "0.850000: A_0249_1.LEFT_CC.LJPEG.png\n",
      "0.900000: A_1104_1.RIGHT_CC.LJPEG.png\n",
      "0.950000: A_0710_1.RIGHT_CC.LJPEG.png\n",
      "(1000, 150, 150)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Actually load some representative data for model experimentation\n",
    "maxData = 1000\n",
    "X_data, Y_data = bc.load_data(dataPath, imagePath, maxData = maxData, verboseFreq = 50, imgResize=imgResize)\n",
    "print X_data.shape\n",
    "print Y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training/Test Sets\n",
    "The following code segment splits the data into training and test data sets. Currently this is a standard 80/20 split for training and test respectively after performing a random shuffle using the unison_shuffled_copies help method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skippedTransforms = True\n",
    "if skippedTransforms:\n",
    "    X_data2 = X_data\n",
    "    Y_data2 = Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "(800, 150, 150)\n",
      "(200, 150, 150)\n",
      "(800, 1)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into Training and Test sets\n",
    "trainNdx = int(X_data2.shape[0] * .8)\n",
    "print trainNdx\n",
    "\n",
    "X_train, X_test = np.split(X_data2, [trainNdx])\n",
    "Y_train, Y_test = np.split(Y_data2, [trainNdx])\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "\n",
    "print Y_train.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'benign': 0, 'malignant': 1}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Load the bc array for our count in the model definition\n",
    "bcTypes = bc.bcNumerics()\n",
    "print bcTypes\n",
    "print len(bcTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 32, 143, 143)2080        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 32, 143, 143)0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 32, 71, 71)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 32, 67, 67)  25632       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 32, 67, 67)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)      (None, 32, 33, 33)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)    (None, 64, 31, 31)  18496       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 64, 31, 31)  0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)      (None, 64, 15, 15)  0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)    (None, 64, 14, 14)  16448       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 64, 14, 14)  0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)      (None, 64, 7, 7)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 3136)        0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 64)          200768      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)          (None, 64)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 2)           130         activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)          (None, 2)           0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 263554\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Construct the model using our help function\n",
    "model = models.bc_model_v0(len(bcTypes), verbose=True, \n",
    "                                        input_shape=(1,X_train.shape[1],X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "The following code segment trains the model using the run_network helper function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadWeights = False\n",
    "if loadWeights:\n",
    "    model.load_weights(\"dwdii-bc-150-v0-Cloud.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape to the appropriate shape for the CNN input\n",
    "testX = X_test.reshape(X_test.shape[0], 1, X_train.shape[1],X_train.shape[2])\n",
    "trainX = X_train.reshape(X_train.shape[0], 1, X_train.shape[1],X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start: 2017-03-20 03:12:14.703137\n",
      "(800, 2)\n",
      "(200, 2)\n",
      "Training model...\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "800/800 [==============================] - 187s - loss: 0.7914 - acc: 0.7275 - val_loss: 0.5522 - val_acc: 0.7250\n",
      "Epoch 2/30\n",
      "800/800 [==============================] - 205s - loss: 0.5123 - acc: 0.7537 - val_loss: 0.5719 - val_acc: 0.7250\n",
      "Epoch 3/30\n",
      "800/800 [==============================] - 190s - loss: 0.5097 - acc: 0.7562 - val_loss: 0.5951 - val_acc: 0.7200\n",
      "Epoch 4/30\n",
      "800/800 [==============================] - 217s - loss: 0.5197 - acc: 0.7550 - val_loss: 0.6463 - val_acc: 0.7250\n",
      "Epoch 5/30\n",
      "800/800 [==============================] - 188s - loss: 0.4833 - acc: 0.7537 - val_loss: 0.6101 - val_acc: 0.5350\n",
      "Epoch 6/30\n",
      "800/800 [==============================] - 184s - loss: 0.5127 - acc: 0.7325 - val_loss: 0.6077 - val_acc: 0.7200\n",
      "Epoch 7/30\n",
      "800/800 [==============================] - 185s - loss: 0.4787 - acc: 0.7338 - val_loss: 0.5629 - val_acc: 0.7150\n",
      "Epoch 8/30\n",
      "800/800 [==============================] - 185s - loss: 0.4702 - acc: 0.7538 - val_loss: 0.5606 - val_acc: 0.7300\n",
      "Epoch 9/30\n",
      "800/800 [==============================] - 186s - loss: 0.4642 - acc: 0.7538 - val_loss: 0.5514 - val_acc: 0.6800\n",
      "Epoch 10/30\n",
      "800/800 [==============================] - 182s - loss: 0.4417 - acc: 0.7750 - val_loss: 0.6053 - val_acc: 0.7050\n",
      "Epoch 11/30\n",
      "800/800 [==============================] - 184s - loss: 0.4304 - acc: 0.7675 - val_loss: 0.5665 - val_acc: 0.7000\n",
      "Epoch 12/30\n",
      "800/800 [==============================] - 185s - loss: 0.4077 - acc: 0.7787 - val_loss: 0.6497 - val_acc: 0.7300\n",
      "Epoch 13/30\n",
      "800/800 [==============================] - 184s - loss: 0.3841 - acc: 0.7888 - val_loss: 0.6031 - val_acc: 0.7000\n",
      "Epoch 14/30\n",
      "800/800 [==============================] - 214s - loss: 0.3803 - acc: 0.8112 - val_loss: 0.6365 - val_acc: 0.7200\n",
      "Epoch 15/30\n",
      "300/800 [==========>...................] - ETA: 118s - loss: 0.2987 - acc: 0.8500"
     ]
    }
   ],
   "source": [
    "print \"Training start: \" + str(datetime.datetime.now())\n",
    "m, h = models.run_network([trainX, testX, Y_train, Y_test], model, batch=50, epochs=30, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"dwdii-bc-150-v0-Cloud.hdf5\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
