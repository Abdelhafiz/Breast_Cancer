{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import Image\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy import misc\n",
    "import string\n",
    "import time\n",
    "import sys\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# Set some Theano config before initializing\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cpu,floatX=float32,allow_gc=False,openmp=True\"\n",
    "import theano\n",
    "\n",
    "# MatPlotLib - Setup for Jupyter notebook output\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Our modules\n",
    "import dwdii_bc_model_helper as bc\n",
    "import bc_models as models\n",
    "\n",
    "# And Keras so we can emit the version\n",
    "import keras\n",
    "\n",
    "random.seed(20275)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print some upfront version and config settings\n",
    "print \"Python v\" + sys.version\n",
    "print \"Numpy v: \" + np.__version__\n",
    "print \"keras v: \" + keras.__version__\n",
    "print \"device:\", theano.config.device\n",
    "print \"floatX:\",  theano.config.floatX\n",
    "print \"mode:\", theano.config.mode\n",
    "print \"openmp:\", theano.config.openmp\n",
    "print \"allow_gc:\", theano.config.allow_gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imagePath = \"/root/bc_data/ddsm-png.25\"\n",
    "imagePath = \"/root/bc_data/Data_Thresholded/DDSM\"\n",
    "trainImagePath = imagePath\n",
    "trainDataPath = \"../../data/ddsm_train.csv\"\n",
    "\n",
    "categories = bc.bcNormVsAbnormNumerics()\n",
    "normalVsAbnormal = True\n",
    "\n",
    "#\n",
    "# Simulated training data\n",
    "#\n",
    "#trainImagePath = \"/root/bc_data/simulated_images\"\n",
    "#trainDataPath = \"/root/bc_data/simulated_images/simulated_images.csv\"\n",
    "#trainImagePath = \"/root/bc_data/simulated_images_new\"\n",
    "#trainDataPath = \"/root/bc_data/simulated_images_new/simulated_images.csv\"\n",
    "\n",
    "testDataPath = \"../../data/ddsm_test.csv\"\n",
    "imgResize = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir('../../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training and Test Data\n",
    "\n",
    "In this section, the training/validation data is loaded. The load_data function pre-balances the data set by removing images from over-represented emotion classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metaData, meta2, mCounts = bc.load_training_metadata(trainDataPath, balanceViaRemoval=True, verbose=True, \n",
    "                                                     normalVsAbnormal=normalVsAbnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Actually load some representative data for model experimentation\n",
    "maxData = len(metaData)\n",
    "X_data, Y_data = bc.load_data(trainDataPath, trainImagePath, \n",
    "                              categories=categories,\n",
    "                              maxData = maxData, \n",
    "                              verboseFreq = 50, \n",
    "                              imgResize=imgResize, \n",
    "                              normalVsAbnormal=normalVsAbnormal)\n",
    "print X_data.shape\n",
    "print Y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Actually load some representative data for model experimentation\n",
    "maxData = len(metaData)\n",
    "X_test, Y_test = bc.load_data(testDataPath, imagePath, \n",
    "                              categories=categories,\n",
    "                              maxData = maxData, \n",
    "                              verboseFreq = 50, \n",
    "                              imgResize=imgResize, \n",
    "                              normalVsAbnormal=normalVsAbnormal)\n",
    "print X_test.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will apply transformations to the existing images to increase of training data, as well as add a bit of noise in the hopes of improving the overall training activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imgDataGenCount = 12\n",
    "transformCount = 1 #+ imgDataGenCount\n",
    "\n",
    "newImgs = np.zeros([X_data.shape[0] * transformCount, X_data.shape[1], X_data.shape[2]])\n",
    "newYs = np.zeros([Y_data.shape[0] * transformCount, Y_data.shape[1]], dtype=np.int8)\n",
    "print newImgs.shape\n",
    "print newYs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = X_data[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndx = 0\n",
    "for i in range(X_data.shape[0]):\n",
    "    img = X_data[i]\n",
    "    \n",
    "    img0 = bc.reflectY(img)\n",
    "    newImgs[ndx] = img0\n",
    "    newYs[ndx] = Y_data[i]\n",
    "    #misc.imsave(\"test0.png\", img0)\n",
    "    ndx += 1\n",
    "    \n",
    "    \n",
    "    #break\n",
    "    \n",
    "print(\"Done\", str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_data2 = np.concatenate((X_data, newImgs))\n",
    "Y_data2 = np.concatenate((Y_data, newYs))\n",
    "print X_data2.shape\n",
    "print Y_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "performedTransforms = True\n",
    "if performedTransforms:\n",
    "    X_train = X_data2\n",
    "    Y_train = Y_data2\n",
    "else:\n",
    "    X_train = X_data\n",
    "    Y_train = Y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Test Set Distribution\n",
    "The following code segment splits the data into training and test data sets. Currently this is a standard 80/20 split for training and test respectively after performing a random shuffle using the unison_shuffled_copies help method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "\n",
    "print Y_train.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "def yDist(y):\n",
    "    bcCounts = collections.defaultdict(int)\n",
    "    for a in range(0, y.shape[0]):\n",
    "        bcCounts[y[a][0]] += 1\n",
    "    return bcCounts\n",
    "\n",
    "print \"Y_train Dist: \" + str(yDist(Y_train))\n",
    "print \"Y_test Dist: \" + str(yDist(Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the bc array for our count in the model definition\n",
    "print categories\n",
    "print len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the model using our help function\n",
    "model = models.bc_model_v01(len(categories), verbose=True, \n",
    "                                        input_shape=(1,X_train.shape[1],X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "The following code segment trains the model using the run_network helper function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadWeights = False\n",
    "weightsFileName = \"dwdii-bc-v01-normVsabnorm150-thresholded-5474-20170430.hdf5\"\n",
    "if loadWeights:\n",
    "    model.load_weights('weights/' + weightsFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape to the appropriate shape for the CNN input\n",
    "testX = X_test.reshape(X_test.shape[0], 1, X_test.shape[1],X_test.shape[2])\n",
    "trainX = X_train.reshape(X_train.shape[0], 1, X_train.shape[1],X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Training start: \" + str(datetime.datetime.now())\n",
    "m, h = models.run_network([trainX, testX, Y_train, Y_test], model, batch=50, epochs=30, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights/' + weightsFileName, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw DDSM Images\n",
    "\n",
    "Initial results based on \"normal\" being masked as \"benign\":\n",
    "* bc_model_v0 (150x150, 800/200): 182s - loss: 0.0560 - acc: 0.9813 - val_loss: 1.9918 - val_acc: 0.6800\n",
    "* bc_model_v0 (150x150, 2000/500): 473s - loss: 0.0288 - acc: 0.9925 - val_loss: 1.4040 - val_acc: 0.7260\n",
    "   * somewhat balanced, Y_train Dist {0: 1223, 1: 777}, Y_test Dist: {0: 321, 1: 179}\n",
    "\n",
    "Revised with \"normal\", \"benign\" and \"malignant\" labeled seperately:\n",
    "* bc_model_v0 (150x150, 1311/328): 298s - loss: 0.0411 - acc: 0.9786 - val_loss: 1.3713 - val_acc: 0.6616\n",
    "\n",
    "After creating fixed \"train\", \"test\" and \"validate\" data sets, using \"train\" and \"test\" as well as including the DDSM Benign cases:\n",
    "* bc_model_v0 (150x150, 1554/363, 03.27.2017): 264s - loss: 0.0512 - acc: 0.9730 - val_loss: 1.3120 - val_acc: 0.6116\n",
    "* bc_model_v0 (150x150, 2155/539, 04.02.2017): 362s - loss: 0.0600 - acc: 0.9763 - val_loss: 1.5315 - val_acc: 0.4805\n",
    "\n",
    "bc_model_v01 - categorical_crossentropy\n",
    "* bc_model_v01 (150x150, 2155/539, 04.03.2017): 361s - loss: 0.0935 - acc: 0.9800 - val_loss: 2.7872 - val_acc: 0.5065\n",
    "* bc_model_v01 (150x150, 2132/536, 04.05.2017): 369s - loss: 0.0718 - acc: 0.9794 - val_loss: 2.5604 - val_acc: 0.5243\n",
    "\n",
    "#### Thresholded Images\n",
    "\n",
    "Using the \"Data_Thresholded\" images\n",
    "* bc_model_v0 (150x150, Thresholded, 661/171, 03.28.2017): 124s - loss: 0.0529 - acc: 0.9743 - val_loss: 1.4331 - val_acc: 0.4971\n",
    "\n",
    "#### Simulated Images\n",
    "\n",
    "Using the \"simulated_images\" images\n",
    "* bc_model_v01 (150x150, 7776/536, 04.24.2017): 1250s - loss: 0.5543 - acc: 0.7885 - val_loss: 7.1153 - val_acc: 0.4123\n",
    "\n",
    "#### Normal Vs Abnormal\n",
    "\n",
    "##### Raw\n",
    "* bc_model_v01 (150x150, 2893/536, 04.25.2017):  496s - loss: 0.0522 - acc: 0.9865 - val_loss: 2.2328 - val_acc: 0.6309\n",
    "\n",
    "##### Data Thresholded\n",
    "* bc_model_v01 (150x150, 924/231,04.26.2017): 154s - loss: 0.0365 - acc: 0.9892 - val_loss: 1.9738 - val_acc: 0.5628\n",
    "* bc_model_v01 (150x150, 2737/694,04.29.2017): 463s - loss: 0.0390 - acc: 0.9898 - val_loss: 2.4042 - val_acc: 0.6326\n",
    "* bc_model_v01 ((150x150, 5474/694,04.30.2017)): 1317s - loss: 0.0552 - acc: 0.9845 - val_loss: 2.8678 - val_acc: 0.6138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultsValAcc = {}\n",
    "#resultsValAcc[\"1\"] = 0.6800\n",
    "#resultsValAcc[\"2\"] = 0.7260\n",
    "#resultsValAcc[\"3\"] = 0.6616\n",
    "#resultsValAcc[\"03-27-2017\"] = 0.6116\n",
    "#resultsValAcc[\"04-02-2017\"] = 0.4805\n",
    "#resultsValAcc[\"04-03-2017\"] = 0.5065\n",
    "#resultsValAcc[\"04-05-2017\"] = 0.5243\n",
    "resultsValAcc[924] = 0.5628\n",
    "resultsValAcc[2737] = 0.6326\n",
    "resultsValAcc[5474] = 0.6138\n",
    "import dwdii_test as dwdii\n",
    "#cmp = matplotlib.colors.Colormap(\"Blues\")\n",
    "dwdii.barChart(resultsValAcc, filename=\"../../figures/shallowCnn_thresholded_2class_results_valacc.png\", title=\"Shallow CNN - DDSM Data Thresholded 2 Class Test Accuracy\", yAxisLabel=\"Accuracy %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Predictions with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictOutput = model.predict(testX, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predClass = np.array(predictOutput[0]).argmax()\n",
    "numBC = bc.reverseDict(categories)\n",
    "numBC[predClass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numBC[Y_test[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predClasses = []\n",
    "for i in range(len(predictOutput)):\n",
    "\n",
    "    arPred = np.array(predictOutput[i])\n",
    "    predictionProb = arPred.max()\n",
    "    predictionNdx = arPred.argmax()\n",
    "    predClassName = numBC[predictionNdx]\n",
    "    predClasses.append(predictionNdx)\n",
    "\n",
    "    #print \"{0}: {1} ({2})\".format(i, predClassName, predictionProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use sklearn's helper method to generate the confusion matrix\n",
    "cnf_matrix = skm.confusion_matrix(Y_test, predClasses)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_names = numBC.values()\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "fileCfMatrix = '../../figures/confusion_matrix-' + weightsFileName + '.png'\n",
    "plt.figure()\n",
    "bc.plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization, \\n' + weightsFileName)\n",
    "plt.savefig(fileCfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the image we just saved\n",
    "from IPython.display import Image\n",
    "Image(filename=fileCfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "fileCfMatrixNorm = '../../figures/confusion_matrix_norm-' + weightsFileName + '.png'\n",
    "plt.figure()\n",
    "bc.plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix \\n' + weightsFileName)\n",
    "plt.savefig(fileCfMatrixNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the image we just saved\n",
    "from IPython.display import Image\n",
    "Image(filename=fileCfMatrixNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
