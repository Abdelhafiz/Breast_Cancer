{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import Image\n",
    "import gc\n",
    "import numpy as np # pip install numpy --upgrade \n",
    "import os\n",
    "import random\n",
    "from scipy import misc\n",
    "import string\n",
    "import time\n",
    "import sys\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# Set some Theano config before initializing\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cpu,floatX=float32,allow_gc=False,openmp=True\"\n",
    "import theano\n",
    "\n",
    "# MatPlotLib - Setup for Jupyter notebook output\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Our modules\n",
    "import dwdii_bc_model_helper as bc\n",
    "import bc_models as models\n",
    "\n",
    "# And Keras so we can emit the version\n",
    "import keras\n",
    "\n",
    "random.seed(20275)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python v2.7.6 (default, Jun 22 2015, 17:58:13) \n",
      "[GCC 4.8.2]\n",
      "Numpy v: 1.12.1\n",
      "keras v: 1.0.3\n",
      "device: cpu\n",
      "floatX: float32\n",
      "mode: FAST_RUN\n",
      "openmp: True\n",
      "allow_gc: False\n"
     ]
    }
   ],
   "source": [
    "# Print some upfront version and config settings\n",
    "print \"Python v\" + sys.version\n",
    "print \"Numpy v: \" + np.__version__\n",
    "print \"keras v: \" + keras.__version__\n",
    "print \"device:\", theano.config.device\n",
    "print \"floatX:\",  theano.config.floatX\n",
    "print \"mode:\", theano.config.mode\n",
    "print \"openmp:\", theano.config.openmp\n",
    "print \"allow_gc:\", theano.config.allow_gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePath = \"/root/bc_data/ddsm-png.25\"\n",
    "#imagePath = \"/root/bc_data/Data_Thresholded/DDSM\"\n",
    "trainImagePath = imagePath\n",
    "trainDataPath = \"../../data/ddsm_train.csv\"\n",
    "\n",
    "# 2 Class Experiment? \n",
    "# If not, then default is 3 class experiment\n",
    "normalVsAbnormal = False\n",
    "categories = bc.bcNumerics()\n",
    "thesePathos = [\"benign\", \"malignant\"]\n",
    "if(normalVsAbnormal):\n",
    "     categories = bc.bcNormVsAbnormNumerics()\n",
    "\n",
    "#\n",
    "# Simulated training data\n",
    "#\n",
    "#trainImagePath = \"/root/bc_data/simulated_images\"\n",
    "#trainDataPath = \"/root/bc_data/simulated_images/simulated_images.csv\"\n",
    "#trainImagePath = \"/root/bc_data/simulated_images_new\"\n",
    "#trainDataPath = \"/root/bc_data/simulated_images_new/simulated_images.csv\"\n",
    "\n",
    "# Test data is always from ddsm_test.csv\n",
    "testDataPath = \"../../data/ddsm_test.csv\"\n",
    "imgResize = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ddsm_test.csv', 'ddsm_train.csv', 'ddsm_val.csv', 'mias_all.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training and Test Data\n",
    "\n",
    "In this section, the training/validation data is loaded. The load_data function pre-balances the data set by removing images from over-represented emotion classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Balance\n",
      "----------------\n",
      "benign 531\n",
      "malignant 739\n",
      "normal 2685\n",
      "balanaceViaRemoval.avgE: 1318\n",
      "balanaceViaRemoval.theshold: 1318.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 531\n",
      "malignant 739\n",
      "normal 862\n"
     ]
    }
   ],
   "source": [
    "metaData, meta2, mCounts = bc.load_training_metadata(trainDataPath, balanceViaRemoval=True, verbose=True, \n",
    "                                                     normalVsAbnormal=normalVsAbnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Balance\n",
      "----------------\n",
      "benign 531\n",
      "malignant 739\n",
      "normal 2685\n",
      "balanaceViaRemoval.avgE: 1318\n",
      "balanaceViaRemoval.theshold: 1318.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 531\n",
      "malignant 739\n",
      "normal 862\n",
      "0.0000: C_0418_1.LEFT_CC.LJPEG.png\n",
      "0.0235: C_0035_1.RIGHT_MLO.LJPEG.png\n",
      "0.0469: C_0390_1.LEFT_CC.LJPEG.png\n",
      "0.0704: B_3434_1.LEFT_CC.LJPEG.png\n",
      "0.0938: C_0381_1.RIGHT_CC.LJPEG.png\n",
      "0.1173: C_0350_1.RIGHT_MLO.LJPEG.png\n",
      "0.1407: C_0358_1.LEFT_MLO.LJPEG.png\n",
      "0.1642: B_3156_1.RIGHT_MLO.LJPEG.png\n",
      "0.1876: B_3360_1.RIGHT_MLO.LJPEG.png\n",
      "0.2111: B_3489_1.RIGHT_MLO.LJPEG.png\n",
      "0.2345: C_0016_1.RIGHT_CC.LJPEG.png\n",
      "0.2580: A_1043_1.LEFT_MLO.LJPEG.png\n",
      "0.2814: C_0037_1.LEFT_MLO.LJPEG.png\n",
      "0.3049: B_3027_1.LEFT_MLO.LJPEG.png\n",
      "0.3283: A_1100_1.LEFT_MLO.LJPEG.png\n",
      "0.3518: C_0042_1.LEFT_CC.LJPEG.png\n",
      "0.3752: C_0278_1.RIGHT_CC.LJPEG.png\n",
      "0.3987: C_0276_1.RIGHT_CC.LJPEG.png\n",
      "0.4221: A_1031_1.LEFT_MLO.LJPEG.png\n",
      "0.4456: A_1046_1.RIGHT_MLO.LJPEG.png\n",
      "0.4690: A_1063_1.LEFT_MLO.LJPEG.png\n",
      "0.4925: C_0377_1.RIGHT_CC.LJPEG.png\n",
      "0.5159: C_0025_1.LEFT_CC.LJPEG.png\n",
      "0.5394: B_3367_1.LEFT_MLO.LJPEG.png\n",
      "0.5629: B_3001_1.LEFT_CC.LJPEG.png\n",
      "0.5863: B_3432_1.RIGHT_MLO.LJPEG.png\n",
      "(1270, 150, 150)\n",
      "(1270, 1)\n"
     ]
    }
   ],
   "source": [
    "# Actually load some representative data for model experimentation\n",
    "maxData = len(metaData)\n",
    "X_data, Y_data = bc.load_data(trainDataPath, trainImagePath, \n",
    "                              categories=categories,\n",
    "                              maxData = maxData, \n",
    "                              verboseFreq = 50, \n",
    "                              imgResize=imgResize, \n",
    "                              thesePathos=thesePathos,\n",
    "                              normalVsAbnormal=normalVsAbnormal)\n",
    "print X_data.shape\n",
    "print Y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Balance\n",
      "----------------\n",
      "benign 142\n",
      "malignant 179\n",
      "normal 658\n",
      "balanaceViaRemoval.avgE: 326\n",
      "balanaceViaRemoval.theshold: 326.0\n",
      "\n",
      "After Balancing\n",
      "----------------\n",
      "benign 142\n",
      "malignant 179\n",
      "normal 215\n",
      "0.0000: B_3380_1.RIGHT_MLO.LJPEG.png\n",
      "0.0235: C_0241_1.LEFT_MLO.LJPEG.png\n",
      "0.0469: C_0044_1.LEFT_MLO.LJPEG.png\n",
      "0.0704: B_3003_1.RIGHT_MLO.LJPEG.png\n",
      "0.0938: C_0241_1.LEFT_CC.LJPEG.png\n",
      "0.1173: B_3013_1.RIGHT_MLO.LJPEG.png\n",
      "0.1407: C_0103_1.LEFT_CC.LJPEG.png\n",
      "(321, 150, 150)\n",
      "(321, 1)\n"
     ]
    }
   ],
   "source": [
    "# Actually load some representative data for model experimentation\n",
    "maxData = len(metaData)\n",
    "X_test, Y_test = bc.load_data(testDataPath, imagePath, \n",
    "                              categories=categories,\n",
    "                              maxData = maxData, \n",
    "                              verboseFreq = 50, \n",
    "                              imgResize=imgResize, \n",
    "                              thesePathos=thesePathos,\n",
    "                              normalVsAbnormal=normalVsAbnormal)\n",
    "print X_test.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will apply transformations to the existing images to increase of training data, as well as add a bit of noise in the hopes of improving the overall training activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12700, 150, 150)\n",
      "(12700, 1)\n"
     ]
    }
   ],
   "source": [
    "imgDataGenCount = 10\n",
    "transformCount = imgDataGenCount\n",
    "\n",
    "newImgs = np.zeros([X_data.shape[0] * transformCount, X_data.shape[1], X_data.shape[2]])\n",
    "newYs = np.zeros([Y_data.shape[0] * transformCount, Y_data.shape[1]], dtype=np.int8)\n",
    "print newImgs.shape\n",
    "print newYs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = X_data[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done', '2017-05-03 02:20:06.342797')\n"
     ]
    }
   ],
   "source": [
    "ndx = 0\n",
    "for i in range(X_data.shape[0]):\n",
    "    img = X_data[i]\n",
    "   \n",
    "    for n in range(imgDataGenCount):\n",
    "            imgX = models.imageDataGenTransform(img, Y_data[i])\n",
    "            imgX = imgX.reshape(150, 150)\n",
    "            \n",
    "            #print imgX.shape\n",
    "            newImgs[ndx] = imgX\n",
    "            newYs[ndx] = Y_data[i]\n",
    "            #misc.imsave(\"testX.png\", imgX)\n",
    "            ndx += 1    \n",
    "    \n",
    "    #break\n",
    "    \n",
    "print(\"Done\", str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13970, 150, 150)\n",
      "(13970, 1)\n"
     ]
    }
   ],
   "source": [
    "X_data2 = np.concatenate((X_data, newImgs))\n",
    "Y_data2 = np.concatenate((Y_data, newYs))\n",
    "print X_data2.shape\n",
    "print Y_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "performedTransforms = True\n",
    "if performedTransforms:\n",
    "    X_train = X_data2\n",
    "    Y_train = Y_data2\n",
    "else:\n",
    "    X_train = X_data\n",
    "    Y_train = Y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Test Set Distribution\n",
    "The following code segment splits the data into training and test data sets. Currently this is a standard 80/20 split for training and test respectively after performing a random shuffle using the unison_shuffled_copies help method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13970, 150, 150)\n",
      "(321, 150, 150)\n",
      "(13970, 1)\n",
      "(321, 1)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "\n",
    "print Y_train.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train Dist: defaultdict(<type 'int'>, {1: 5841, 2: 8129})\n",
      "Y_test Dist: defaultdict(<type 'int'>, {1: 142, 2: 179})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "def yDist(y):\n",
    "    bcCounts = collections.defaultdict(int)\n",
    "    for a in range(0, y.shape[0]):\n",
    "        bcCounts[y[a][0]] += 1\n",
    "    return bcCounts\n",
    "\n",
    "print \"Y_train Dist: \" + str(yDist(Y_train))\n",
    "print \"Y_test Dist: \" + str(yDist(Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'benign': 1, 'malignant': 2, 'normal': 0}\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load the bc array for our count in the model definition\n",
    "print categories\n",
    "print len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 32, 143, 143)2080        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 32, 143, 143)0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 32, 71, 71)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 32, 67, 67)  25632       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 32, 67, 67)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)      (None, 32, 33, 33)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)    (None, 64, 31, 31)  18496       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 64, 31, 31)  0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)      (None, 64, 15, 15)  0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)    (None, 64, 14, 14)  16448       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 64, 14, 14)  0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)      (None, 64, 7, 7)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 3136)        0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 64)          200768      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)          (None, 64)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 3)           195         activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)          (None, 3)           0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 263619\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Construct the model using our help function\n",
    "model = models.bc_model_v01(len(categories), verbose=True, \n",
    "                                        input_shape=(1,X_train.shape[1],X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "The following code segment trains the model using the run_network helper function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadWeights = False\n",
    "weightsFileName = \"dwdii-bc-v01-150-benignMalignant-13970-20170502.hdf5\"\n",
    "if loadWeights:\n",
    "    model.load_weights('weights/' + weightsFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape to the appropriate shape for the CNN input\n",
    "testX = X_test.reshape(X_test.shape[0], 1, X_test.shape[1],X_test.shape[2])\n",
    "trainX = X_train.reshape(X_train.shape[0], 1, X_train.shape[1],X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start: 2017-05-03 02:26:55.989589\n",
      "(13970, 3)\n",
      "(321, 3)\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13970 samples, validate on 321 samples\n",
      "Epoch 1/50\n",
      " 2000/13970 [===>..........................] - ETA: 2272s - loss: 0.7408 - acc: 0.5560"
     ]
    }
   ],
   "source": [
    "print \"Training start: \" + str(datetime.datetime.now())\n",
    "m, h = models.run_network([trainX, testX, Y_train, Y_test], model, batch=50, epochs=50, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights/' + weightsFileName, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw DDSM Images\n",
    "\n",
    "Initial results based on \"normal\" being masked as \"benign\":\n",
    "* bc_model_v0 (150x150, 800/200): 182s - loss: 0.0560 - acc: 0.9813 - val_loss: 1.9918 - val_acc: 0.6800\n",
    "* bc_model_v0 (150x150, 2000/500): 473s - loss: 0.0288 - acc: 0.9925 - val_loss: 1.4040 - val_acc: 0.7260\n",
    "   * somewhat balanced, Y_train Dist {0: 1223, 1: 777}, Y_test Dist: {0: 321, 1: 179}\n",
    "\n",
    "Revised with \"normal\", \"benign\" and \"malignant\" labeled seperately:\n",
    "* bc_model_v0 (150x150, 1311/328): 298s - loss: 0.0411 - acc: 0.9786 - val_loss: 1.3713 - val_acc: 0.6616\n",
    "\n",
    "After creating fixed \"train\", \"test\" and \"validate\" data sets, using \"train\" and \"test\" as well as including the DDSM Benign cases:\n",
    "* bc_model_v0 (150x150, 1554/363, 03.27.2017): 264s - loss: 0.0512 - acc: 0.9730 - val_loss: 1.3120 - val_acc: 0.6116\n",
    "* bc_model_v0 (150x150, 2155/539, 04.02.2017): 362s - loss: 0.0600 - acc: 0.9763 - val_loss: 1.5315 - val_acc: 0.4805\n",
    "\n",
    "bc_model_v01 - categorical_crossentropy\n",
    "* bc_model_v01 (150x150, 2155/539, 04.03.2017): 361s - loss: 0.0935 - acc: 0.9800 - val_loss: 2.7872 - val_acc: 0.5065\n",
    "* bc_model_v01 (150x150, 2132/536, 04.05.2017): 369s - loss: 0.0718 - acc: 0.9794 - val_loss: 2.5604 - val_acc: 0.5243\n",
    "\n",
    "#### Thresholded Images\n",
    "\n",
    "Using the \"Data_Thresholded\" images\n",
    "* bc_model_v0 (150x150, Thresholded, 661/171, 03.28.2017): 124s - loss: 0.0529 - acc: 0.9743 - val_loss: 1.4331 - val_acc: 0.4971\n",
    "\n",
    "#### Simulated Images\n",
    "\n",
    "Using the \"simulated_images\" images\n",
    "* bc_model_v01 (150x150, 7776/536, 04.24.2017): 1250s - loss: 0.5543 - acc: 0.7885 - val_loss: 7.1153 - val_acc: 0.4123\n",
    "\n",
    "Using the \"simulated_images_new\" images\n",
    "* bc_model_v01 (150x150, 7776/536, 04.30.2017): 1242s - loss: 10.1318 - acc: 0.3714 - val_loss: 6.7477 - val_acc: 0.3340\n",
    "\n",
    "#### Normal Vs Abnormal\n",
    "\n",
    "##### Raw\n",
    "* bc_model_v01 (150x150, 2893/536, 04.25.2017):  496s - loss: 0.0522 - acc: 0.9865 - val_loss: 2.2328 - val_acc: 0.6309\n",
    "\n",
    "##### Data Thresholded\n",
    "* bc_model_v01 (150x150, 924/231,04.26.2017): 154s - loss: 0.0365 - acc: 0.9892 - val_loss: 1.9738 - val_acc: 0.5628\n",
    "* bc_model_v01 (150x150, 2737/694,04.29.2017): 463s - loss: 0.0390 - acc: 0.9898 - val_loss: 2.4042 - val_acc: 0.6326\n",
    "* bc_model_v01 ((150x150, 5474/694,04.30.2017)): 1317s - loss: 0.0552 - acc: 0.9845 - val_loss: 2.8678 - val_acc: 0.6138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultsValAcc = {}\n",
    "#resultsValAcc[\"1\"] = 0.6800\n",
    "#resultsValAcc[\"2\"] = 0.7260\n",
    "#resultsValAcc[\"3\"] = 0.6616\n",
    "#resultsValAcc[\"03-27-2017\"] = 0.6116\n",
    "#resultsValAcc[\"04-02-2017\"] = 0.4805\n",
    "#resultsValAcc[\"04-03-2017\"] = 0.5065\n",
    "#resultsValAcc[\"04-05-2017\"] = 0.5243\n",
    "resultsValAcc[924] = 0.5628\n",
    "resultsValAcc[2737] = 0.6326\n",
    "resultsValAcc[5474] = 0.6138\n",
    "import dwdii_test as dwdii\n",
    "#cmp = matplotlib.colors.Colormap(\"Blues\")\n",
    "dwdii.barChart(resultsValAcc, filename=\"../../figures/shallowCnn_thresholded_2class_results_valacc.png\", title=\"Shallow CNN - DDSM Data Thresholded 2 Class Test Accuracy\", yAxisLabel=\"Accuracy %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Predictions with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictOutput = model.predict(testX, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predClass = np.array(predictOutput[0]).argmax()\n",
    "numBC = bc.reverseDict(categories)\n",
    "numBC[predClass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numBC[Y_test[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predClasses = []\n",
    "for i in range(len(predictOutput)):\n",
    "\n",
    "    arPred = np.array(predictOutput[i])\n",
    "    predictionProb = arPred.max()\n",
    "    predictionNdx = arPred.argmax()\n",
    "    predClassName = numBC[predictionNdx]\n",
    "    predClasses.append(predictionNdx)\n",
    "\n",
    "    #print \"{0}: {1} ({2})\".format(i, predClassName, predictionProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use sklearn's helper method to generate the confusion matrix\n",
    "cnf_matrix = skm.confusion_matrix(Y_test, predClasses)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_names = numBC.values()\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "fileCfMatrix = '../../figures/confusion_matrix-' + weightsFileName + '.png'\n",
    "plt.figure()\n",
    "bc.plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization, \\n' + weightsFileName)\n",
    "plt.savefig(fileCfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the image we just saved\n",
    "from IPython.display import Image\n",
    "Image(filename=fileCfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "fileCfMatrixNorm = '../../figures/confusion_matrix_norm-' + weightsFileName + '.png'\n",
    "plt.figure()\n",
    "bc.plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix \\n' + weightsFileName)\n",
    "plt.savefig(fileCfMatrixNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the image we just saved\n",
    "from IPython.display import Image\n",
    "Image(filename=fileCfMatrixNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
